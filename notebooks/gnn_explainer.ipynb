{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2b4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69510dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GNNExplainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class GNNExplainerUpdated(GNNExplainer):\n",
    "    \"\"\" \n",
    "    https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/nn/models/gnn_explainer.py \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def explain_graph(self, x, edge_index, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for a graph.\n",
    "        Args:\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        # all nodes belong to same graph\n",
    "        batch = torch.zeros(x.shape[0], dtype=int, device=x.device)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, batch=batch, **kwargs)\n",
    "            log_logits = self.__to_log_prob__(out)\n",
    "            pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],\n",
    "                                     lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description('Explain graph')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.view(1, -1).sigmoid()\n",
    "            out = self.model(x=h, edge_index=edge_index, batch=batch, **kwargs)\n",
    "            log_logits = self.__to_log_prob__(out)\n",
    "            loss = self.__loss__(-1, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        edge_mask = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return node_feat_mask, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c427c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeeperGCN(\n",
       "  (layers): ModuleList(\n",
       "    (0): DeepLayer(\n",
       "      (layer): DeepGCNLayer(block=res+)\n",
       "      (encoder): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (1): DeepLayer(\n",
       "      (layer): DeepGCNLayer(block=res+)\n",
       "      (encoder): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (2): DeepLayer(\n",
       "      (layer): DeepGCNLayer(block=res+)\n",
       "      (encoder): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "    (3): DeepLayer(\n",
       "      (layer): DeepGCNLayer(block=res+)\n",
       "      (encoder): Linear(in_features=32, out_features=16, bias=True)\n",
       "    )\n",
       "    (4): DeepLayer(\n",
       "      (layer): DeepGCNLayer(block=res+)\n",
       "      (encoder): Linear(in_features=16, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (in_encoder): Linear(in_features=6, out_features=256, bias=True)\n",
       "  (lin): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DeeperGCN\n",
    "\n",
    "model = DeeperGCN(5, 256, device)\n",
    "model.load_state_dict(torch.load('gnn.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a974360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:07<00:00, 13.38it/s]\n",
      "/notebooks/utils/mesh.py:53: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.normals[i, :] = n/np.linalg.norm(n)\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.15it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.14it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.12it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.15it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.12it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.14it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.15it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.12it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.12it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.12it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.15it/s]\n",
      "Explain graph:   2%|▏         | 2/100 [00:00<00:05, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.15it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.14it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 100/100 [00:06<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25\n"
     ]
    }
   ],
   "source": [
    "from graph_data import GraphData\n",
    "from utils.mesh import Mesh\n",
    "\n",
    "graph_data = GraphData()\n",
    "\n",
    "length = graph_data.points // 3\n",
    "\n",
    "node_relevance = [[] for i in range(length)]\n",
    "node_count = [0 for i in range(length)]\n",
    "\n",
    "def node_relevance_mean(node_relevance, node_count):\n",
    "    _node_relevance_mean = []\n",
    "    for idx, count in enumerate(node_count):\n",
    "        mean = sum(node_relevance[idx]) / count\n",
    "        _node_relevance_mean.append(mean)\n",
    "        \n",
    "    return _node_relevance_mean\n",
    "\n",
    "def node_relevance_std(node_relevance, node_count):\n",
    "    _node_relevance_std = []\n",
    "    for idx, count in enumerate(node_count):\n",
    "        mean = sum(node_relevance[idx]) / count\n",
    "        var = sum([(i - mean)**2 for i in node_relevance[idx]]) / count\n",
    "        std = var ** 0.5\n",
    "        _node_relevance_std.append(std)\n",
    "        \n",
    "    return _node_relevance_std\n",
    "\n",
    "def calculate_node_relevance(edge_index, edge_mask):\n",
    "    global node_relevance\n",
    "    global node_count\n",
    "    \n",
    "    _node_relevance = [[] for i in range(graph_data.points//3)]\n",
    "    _node_count = [0 for i in range(length)]\n",
    "    \n",
    "    for edge, relevance in zip(edge_index, edge_mask):\n",
    "        _node_relevance[edge[0]].append(relevance)\n",
    "        _node_relevance[edge[1]].append(relevance)\n",
    "        _node_count[edge[0]] += 1\n",
    "        _node_count[edge[1]] += 1\n",
    "        \n",
    "    # update global node_relevance and node_count\n",
    "    node_relevance = [a + b for a, b in zip(node_relevance, _node_relevance)]\n",
    "    node_count  = [a + b for a, b in zip(node_count, _node_count)]\n",
    "        \n",
    "    return (_node_relevance, _node_count)\n",
    "        \n",
    "    \n",
    "\n",
    "explainer = GNNExplainerUpdated(model, epochs=100, return_type='log_prob')\n",
    "\n",
    "count = 0\n",
    "epochs = 25\n",
    "\n",
    "while count < epochs:\n",
    "    random_sample = graph_data.return_random_graph().to(device)\n",
    "    \n",
    "    if random_sample.y == 1:\n",
    "        _node_feat_mask, _edge_mask = explainer.explain_graph(\n",
    "            random_sample.x, random_sample.edge_index\n",
    "        )\n",
    "        \n",
    "        random_sample = random_sample.to('cpu')\n",
    "        \n",
    "        edge_index = random_sample.edge_index.numpy().T\n",
    "        \n",
    "        edge_mask = _edge_mask.to('cpu').numpy()\n",
    "        \n",
    "        _node_relevance, _node_count = calculate_node_relevance(edge_index, edge_mask)\n",
    "        _node_relevance_mean = node_relevance_mean(_node_relevance, _node_count)\n",
    "        _node_relevance_std = node_relevance_std(_node_relevance, _node_count)\n",
    "        \n",
    "        count += 1\n",
    "        print(f'{count}/{epochs}')\n",
    "                \n",
    "        mesh = Mesh(verts=random_sample.pos.numpy(), connectivity=random_sample.face.numpy().T)\n",
    "        mesh.writeVTU(filename=f'gnn_explainer_results/random_sample_mean_{count}.vtu', scalars=_node_relevance_mean)\n",
    "        mesh.writeVTU(filename=f'gnn_explainer_results/random_sample_std_{count}.vtu', scalars=_node_relevance_std)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd05851",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_relevance_mean = node_relevance_mean(node_relevance, node_count)\n",
    "node_relevance_std = node_relevance_std(node_relevance, node_count)\n",
    "mesh = Mesh(verts=random_sample.pos.numpy(), connectivity=random_sample.face.numpy().T)\n",
    "mesh.writeVTU(filename=f'gnn_explainer_results/random_sample_final_mean.vtu', scalars=node_relevance_mean)\n",
    "mesh.writeVTU(filename=f'gnn_explainer_results/random_sample_final_std.vtu', scalars=node_relevance_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
