{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb08191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1505a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import FaceToEdge\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import pyreadr\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class GraphData:\n",
    "    file_points_asymp = path.join(\"lv-ortho-modes\", \"data\", \"surface_points_ASYMP.RData\")\n",
    "    file_points_mi = path.join(\"lv-ortho-modes\", \"data\", \"surface_points_MI.RData\")\n",
    "    file_face = path.join(\"lv-ortho-modes\", \"data\", \"surface_face.RData\")\n",
    "\n",
    "    df_points_asymp = pyreadr.read_r(file_points_asymp)[\"X.ASYMP\"]\n",
    "    df_points_mi = pyreadr.read_r(file_points_mi)[\"X.MI\"]\n",
    "    df_faces = pyreadr.read_r(file_face)[\"faces\"]\n",
    "    \n",
    "    points = 2523\n",
    "    \n",
    "    def __init__(self, train_x: int=200, train_y: int=200, test_x: int=100, test_y: int=100) -> None:\n",
    "        self.split_into_train_test(train_x, train_y, test_x, test_y)\n",
    "        self.normalize_data()\n",
    "        self.create_loader()\n",
    "        \n",
    "    def _split_points(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, ...]:    \n",
    "        # order: [ED-endo ED-epi ES-endo ES-epi]\n",
    "        \n",
    "        \n",
    "        ed_endo = df.iloc[:, :self.points]\n",
    "        ed_epi = df.iloc[:, self.points:self.points*2]\n",
    "        es_endo = df.iloc[:, self.points*2:self.points*3]\n",
    "        es_epi = df.iloc[:, self.points*3:self.points*4]\n",
    "        \n",
    "        return (ed_endo, ed_epi, es_endo, es_epi)\n",
    "    \n",
    "    def split_into_train_test(self, train_x: int, train_y: int, test_x: int, test_y: int) -> None:\n",
    "    \n",
    "        points = { \"ed_endo\": {}, \"es_endo\": {} }\n",
    "        \n",
    "        points[\"ed_endo\"][\"asymp\"], _, points[\"es_endo\"][\"asymp\"], _ = self._split_points(self.df_points_asymp)\n",
    "        points[\"ed_endo\"][\"mi\"], _, points[\"es_endo\"][\"mi\"], _ = self._split_points(self.df_points_mi)\n",
    "        \n",
    "        transformer = FaceToEdge(True)\n",
    "        \n",
    "        self.train_samples = []\n",
    "        self.test_samples = []\n",
    "\n",
    "        faces = torch.tensor(self.df_faces.values - 1, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        def create_data(start: int, end: int, ed_endo: pd.DataFrame, \n",
    "                        es_endo: pd.DataFrame, y: bool, list_: list\n",
    "                       ) -> None:\n",
    "            for ed, es in zip(ed_endo.values[start:end], es_endo.values[start:end]):\n",
    "                pos_ed = torch.tensor(ed.reshape(self.points//3, 3), dtype=torch.float)\n",
    "                pos_es = torch.tensor(es.reshape(self.points//3, 3), dtype=torch.float)\n",
    "                data = Data(pos=pos_ed, face=faces, y=y)\n",
    "                data.x = torch.tensor(np.concatenate((pos_ed, pos_es), axis=1))\n",
    "                list_.append(transformer(data))\n",
    "                \n",
    "        create_data(0, train_x, points[\"ed_endo\"][\"asymp\"], points[\"es_endo\"][\"asymp\"], 0, self.train_samples)\n",
    "        create_data(0, train_y, points[\"ed_endo\"][\"mi\"], points[\"es_endo\"][\"mi\"], 1, self.train_samples)\n",
    "        create_data(train_x, train_x + test_x, points[\"ed_endo\"][\"asymp\"], points[\"es_endo\"][\"asymp\"], 0, self.test_samples)\n",
    "        create_data(train_y, train_y + test_y, points[\"ed_endo\"][\"mi\"], points[\"es_endo\"][\"mi\"], 1, self.test_samples)\n",
    "        \n",
    "    def normalize_data(self) -> None:\n",
    "        input_features = torch.cat([data.x for data in self.train_samples], axis=0)\n",
    "        inputs_mean, inputs_std = torch.mean(input_features), torch.std(input_features)\n",
    "        \n",
    "        def normalize_set(dataset: list) -> None:\n",
    "            for data in dataset:\n",
    "                data.x = ((data.x - inputs_mean) / inputs_std)\n",
    "            return dataset\n",
    "                \n",
    "        self.train_samples = normalize_set(self.train_samples)\n",
    "        self.test_samples = normalize_set(self.test_samples)\n",
    "        \n",
    "    def create_loader(self) -> None:\n",
    "        self.train_loader = DataLoader(self.train_samples, batch_size=128, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_samples, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ae2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, device=device):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(6, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5575, Test Acc: 0.5650\n",
      "Epoch: 002, Train Acc: 0.5700, Test Acc: 0.5650\n",
      "Epoch: 003, Train Acc: 0.5075, Test Acc: 0.5150\n",
      "Epoch: 004, Train Acc: 0.7100, Test Acc: 0.6750\n",
      "Epoch: 005, Train Acc: 0.7050, Test Acc: 0.7150\n",
      "Epoch: 006, Train Acc: 0.8700, Test Acc: 0.8600\n",
      "Epoch: 007, Train Acc: 0.8675, Test Acc: 0.8550\n",
      "Epoch: 008, Train Acc: 0.9075, Test Acc: 0.8700\n",
      "Epoch: 009, Train Acc: 0.9000, Test Acc: 0.8750\n",
      "Epoch: 010, Train Acc: 0.8575, Test Acc: 0.8450\n",
      "Epoch: 011, Train Acc: 0.8825, Test Acc: 0.8600\n",
      "Epoch: 012, Train Acc: 0.8875, Test Acc: 0.8800\n",
      "Epoch: 013, Train Acc: 0.9025, Test Acc: 0.8800\n",
      "Epoch: 014, Train Acc: 0.9000, Test Acc: 0.8700\n",
      "Epoch: 015, Train Acc: 0.9100, Test Acc: 0.8850\n",
      "Epoch: 016, Train Acc: 0.9075, Test Acc: 0.8850\n",
      "Epoch: 017, Train Acc: 0.9100, Test Acc: 0.8900\n",
      "Epoch: 018, Train Acc: 0.9050, Test Acc: 0.8700\n",
      "Epoch: 019, Train Acc: 0.9225, Test Acc: 0.8850\n",
      "Epoch: 020, Train Acc: 0.9150, Test Acc: 0.8950\n",
      "Epoch: 021, Train Acc: 0.8250, Test Acc: 0.8400\n",
      "Epoch: 022, Train Acc: 0.8950, Test Acc: 0.8850\n",
      "Epoch: 023, Train Acc: 0.9300, Test Acc: 0.8800\n",
      "Epoch: 024, Train Acc: 0.9300, Test Acc: 0.8850\n",
      "Epoch: 025, Train Acc: 0.9200, Test Acc: 0.8900\n",
      "Epoch: 026, Train Acc: 0.9275, Test Acc: 0.8800\n",
      "Epoch: 027, Train Acc: 0.9100, Test Acc: 0.8950\n",
      "Epoch: 028, Train Acc: 0.9100, Test Acc: 0.8750\n",
      "Epoch: 029, Train Acc: 0.9000, Test Acc: 0.8800\n",
      "Epoch: 030, Train Acc: 0.9325, Test Acc: 0.8900\n",
      "Epoch: 031, Train Acc: 0.9225, Test Acc: 0.8800\n",
      "Epoch: 032, Train Acc: 0.9100, Test Acc: 0.9000\n",
      "Epoch: 033, Train Acc: 0.9250, Test Acc: 0.8800\n",
      "Epoch: 034, Train Acc: 0.9100, Test Acc: 0.9000\n",
      "Epoch: 035, Train Acc: 0.9175, Test Acc: 0.8900\n",
      "Epoch: 036, Train Acc: 0.9375, Test Acc: 0.8850\n",
      "Epoch: 037, Train Acc: 0.9000, Test Acc: 0.8850\n",
      "Epoch: 038, Train Acc: 0.9000, Test Acc: 0.8800\n",
      "Epoch: 039, Train Acc: 0.8825, Test Acc: 0.8550\n",
      "Epoch: 040, Train Acc: 0.8950, Test Acc: 0.8800\n",
      "Epoch: 041, Train Acc: 0.9200, Test Acc: 0.8950\n",
      "Epoch: 042, Train Acc: 0.8750, Test Acc: 0.8500\n",
      "Epoch: 043, Train Acc: 0.9100, Test Acc: 0.8700\n",
      "Epoch: 044, Train Acc: 0.9025, Test Acc: 0.8700\n",
      "Epoch: 045, Train Acc: 0.9225, Test Acc: 0.8750\n",
      "Epoch: 046, Train Acc: 0.9200, Test Acc: 0.8800\n",
      "Epoch: 047, Train Acc: 0.8750, Test Acc: 0.8450\n",
      "Epoch: 048, Train Acc: 0.9100, Test Acc: 0.8750\n",
      "Epoch: 049, Train Acc: 0.9300, Test Acc: 0.8750\n",
      "Epoch: 050, Train Acc: 0.8825, Test Acc: 0.8550\n",
      "Epoch: 051, Train Acc: 0.9250, Test Acc: 0.8800\n",
      "Epoch: 052, Train Acc: 0.9275, Test Acc: 0.8750\n",
      "Epoch: 053, Train Acc: 0.9125, Test Acc: 0.8950\n",
      "Epoch: 054, Train Acc: 0.9275, Test Acc: 0.8950\n",
      "Epoch: 055, Train Acc: 0.9150, Test Acc: 0.8950\n",
      "Epoch: 056, Train Acc: 0.9325, Test Acc: 0.8900\n",
      "Epoch: 057, Train Acc: 0.9300, Test Acc: 0.8750\n",
      "Epoch: 058, Train Acc: 0.9275, Test Acc: 0.8950\n",
      "Epoch: 059, Train Acc: 0.9200, Test Acc: 0.8800\n",
      "Epoch: 060, Train Acc: 0.9050, Test Acc: 0.8750\n",
      "Epoch: 061, Train Acc: 0.9325, Test Acc: 0.8800\n",
      "Epoch: 062, Train Acc: 0.9125, Test Acc: 0.8800\n",
      "Epoch: 063, Train Acc: 0.9125, Test Acc: 0.8750\n",
      "Epoch: 064, Train Acc: 0.9300, Test Acc: 0.8900\n",
      "Epoch: 065, Train Acc: 0.9275, Test Acc: 0.8800\n",
      "Epoch: 066, Train Acc: 0.9175, Test Acc: 0.8900\n",
      "Epoch: 067, Train Acc: 0.9275, Test Acc: 0.8900\n",
      "Epoch: 068, Train Acc: 0.9225, Test Acc: 0.8850\n",
      "Epoch: 069, Train Acc: 0.9275, Test Acc: 0.8900\n",
      "Epoch: 070, Train Acc: 0.9275, Test Acc: 0.8900\n",
      "Epoch: 071, Train Acc: 0.9400, Test Acc: 0.8850\n",
      "Epoch: 072, Train Acc: 0.9300, Test Acc: 0.8950\n",
      "Epoch: 073, Train Acc: 0.9450, Test Acc: 0.8950\n",
      "Epoch: 074, Train Acc: 0.9175, Test Acc: 0.8900\n",
      "Epoch: 075, Train Acc: 0.9450, Test Acc: 0.8800\n",
      "Epoch: 076, Train Acc: 0.9225, Test Acc: 0.8800\n",
      "Epoch: 077, Train Acc: 0.9275, Test Acc: 0.8800\n",
      "Epoch: 078, Train Acc: 0.9375, Test Acc: 0.8800\n",
      "Epoch: 079, Train Acc: 0.9300, Test Acc: 0.8950\n",
      "Epoch: 080, Train Acc: 0.9375, Test Acc: 0.8950\n",
      "Epoch: 081, Train Acc: 0.9400, Test Acc: 0.8900\n",
      "Epoch: 082, Train Acc: 0.9325, Test Acc: 0.9000\n",
      "Epoch: 083, Train Acc: 0.9500, Test Acc: 0.8950\n",
      "Epoch: 084, Train Acc: 0.9475, Test Acc: 0.9000\n",
      "Epoch: 085, Train Acc: 0.9475, Test Acc: 0.9000\n",
      "Epoch: 086, Train Acc: 0.9125, Test Acc: 0.8950\n",
      "Epoch: 087, Train Acc: 0.9475, Test Acc: 0.9100\n",
      "Epoch: 088, Train Acc: 0.8975, Test Acc: 0.8700\n",
      "Epoch: 089, Train Acc: 0.9000, Test Acc: 0.8750\n",
      "Epoch: 090, Train Acc: 0.8550, Test Acc: 0.8300\n",
      "Epoch: 091, Train Acc: 0.9025, Test Acc: 0.8600\n",
      "Epoch: 092, Train Acc: 0.9425, Test Acc: 0.8950\n",
      "Epoch: 093, Train Acc: 0.9400, Test Acc: 0.9000\n",
      "Epoch: 094, Train Acc: 0.9200, Test Acc: 0.8750\n",
      "Epoch: 095, Train Acc: 0.9250, Test Acc: 0.8900\n",
      "Epoch: 096, Train Acc: 0.9225, Test Acc: 0.8900\n",
      "Epoch: 097, Train Acc: 0.9450, Test Acc: 0.9000\n",
      "Epoch: 098, Train Acc: 0.9450, Test Acc: 0.9100\n",
      "Epoch: 099, Train Acc: 0.9250, Test Acc: 0.8950\n",
      "Epoch: 100, Train Acc: 0.9300, Test Acc: 0.8950\n",
      "Epoch: 101, Train Acc: 0.9250, Test Acc: 0.8900\n",
      "Epoch: 102, Train Acc: 0.8975, Test Acc: 0.8800\n"
     ]
    }
   ],
   "source": [
    "graph_data = GraphData()\n",
    "\n",
    "model = GCN(hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in graph_data.train_loader: # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 200):\n",
    "    train()\n",
    "    train_acc = test(graph_data.train_loader)\n",
    "    test_acc = test(graph_data.test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
