{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb08191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e24e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5000, Test Acc: 0.5000, lr: 0.05\n",
      "Epoch: 002, Train Acc: 0.5000, Test Acc: 0.5000, lr: 0.05\n",
      "Epoch: 003, Train Acc: 0.8675, Test Acc: 0.8450, lr: 0.05\n",
      "Epoch: 004, Train Acc: 0.7025, Test Acc: 0.6600, lr: 0.05\n",
      "Epoch: 005, Train Acc: 0.8925, Test Acc: 0.8700, lr: 0.05\n",
      "Epoch: 006, Train Acc: 0.8450, Test Acc: 0.8450, lr: 0.05\n",
      "Epoch: 007, Train Acc: 0.9050, Test Acc: 0.8900, lr: 0.05\n",
      "Epoch: 008, Train Acc: 0.6175, Test Acc: 0.6600, lr: 0.05\n",
      "Epoch: 009, Train Acc: 0.8900, Test Acc: 0.8800, lr: 0.05\n",
      "Epoch: 010, Train Acc: 0.9175, Test Acc: 0.8850, lr: 0.025\n",
      "Epoch: 011, Train Acc: 0.8900, Test Acc: 0.8600, lr: 0.025\n",
      "Epoch: 012, Train Acc: 0.8925, Test Acc: 0.8650, lr: 0.025\n",
      "Epoch: 013, Train Acc: 0.9175, Test Acc: 0.8750, lr: 0.025\n",
      "Epoch: 014, Train Acc: 0.8950, Test Acc: 0.8650, lr: 0.025\n",
      "Epoch: 015, Train Acc: 0.9125, Test Acc: 0.8800, lr: 0.025\n",
      "Epoch: 016, Train Acc: 0.9200, Test Acc: 0.8850, lr: 0.025\n",
      "Epoch: 017, Train Acc: 0.9175, Test Acc: 0.8850, lr: 0.025\n",
      "Epoch: 018, Train Acc: 0.9100, Test Acc: 0.8800, lr: 0.025\n",
      "Epoch: 019, Train Acc: 0.9200, Test Acc: 0.8650, lr: 0.025\n",
      "Epoch: 020, Train Acc: 0.9250, Test Acc: 0.8800, lr: 0.0125\n",
      "Epoch: 021, Train Acc: 0.9175, Test Acc: 0.8850, lr: 0.0125\n",
      "Epoch: 022, Train Acc: 0.8875, Test Acc: 0.8500, lr: 0.0125\n",
      "Epoch: 023, Train Acc: 0.9275, Test Acc: 0.8850, lr: 0.0125\n",
      "Epoch: 024, Train Acc: 0.9350, Test Acc: 0.8850, lr: 0.0125\n",
      "Epoch: 025, Train Acc: 0.9000, Test Acc: 0.8750, lr: 0.0125\n",
      "Epoch: 026, Train Acc: 0.9000, Test Acc: 0.8800, lr: 0.0125\n",
      "Epoch: 027, Train Acc: 0.9350, Test Acc: 0.8850, lr: 0.0125\n",
      "Epoch: 028, Train Acc: 0.8900, Test Acc: 0.8800, lr: 0.0125\n",
      "Epoch: 029, Train Acc: 0.9175, Test Acc: 0.8850, lr: 0.0125\n",
      "Epoch: 030, Train Acc: 0.9300, Test Acc: 0.8950, lr: 0.00625\n",
      "Epoch: 031, Train Acc: 0.9425, Test Acc: 0.8850, lr: 0.00625\n",
      "Epoch: 032, Train Acc: 0.9400, Test Acc: 0.9000, lr: 0.00625\n",
      "Epoch: 033, Train Acc: 0.9075, Test Acc: 0.8900, lr: 0.00625\n",
      "Epoch: 034, Train Acc: 0.9375, Test Acc: 0.8950, lr: 0.00625\n",
      "Epoch: 035, Train Acc: 0.9350, Test Acc: 0.8800, lr: 0.00625\n",
      "Epoch: 036, Train Acc: 0.9475, Test Acc: 0.9000, lr: 0.00625\n",
      "Epoch: 037, Train Acc: 0.9225, Test Acc: 0.9100, lr: 0.00625\n",
      "Epoch: 038, Train Acc: 0.9200, Test Acc: 0.8900, lr: 0.00625\n",
      "Epoch: 039, Train Acc: 0.9450, Test Acc: 0.8900, lr: 0.00625\n",
      "Epoch: 040, Train Acc: 0.9050, Test Acc: 0.8750, lr: 0.003125\n",
      "Epoch: 041, Train Acc: 0.9500, Test Acc: 0.8950, lr: 0.003125\n",
      "Epoch: 042, Train Acc: 0.9475, Test Acc: 0.9050, lr: 0.003125\n",
      "Epoch: 043, Train Acc: 0.9525, Test Acc: 0.9050, lr: 0.003125\n",
      "Epoch: 044, Train Acc: 0.9500, Test Acc: 0.9050, lr: 0.003125\n",
      "Epoch: 045, Train Acc: 0.9475, Test Acc: 0.9000, lr: 0.003125\n",
      "Epoch: 046, Train Acc: 0.9550, Test Acc: 0.9000, lr: 0.003125\n",
      "Epoch: 047, Train Acc: 0.9550, Test Acc: 0.9050, lr: 0.003125\n",
      "Epoch: 048, Train Acc: 0.9550, Test Acc: 0.8950, lr: 0.003125\n",
      "Epoch: 049, Train Acc: 0.9425, Test Acc: 0.9050, lr: 0.003125\n",
      "Epoch: 050, Train Acc: 0.9575, Test Acc: 0.9150, lr: 0.0015625\n",
      "Epoch: 051, Train Acc: 0.9500, Test Acc: 0.9000, lr: 0.0015625\n",
      "Epoch: 052, Train Acc: 0.9625, Test Acc: 0.9100, lr: 0.0015625\n",
      "Epoch: 053, Train Acc: 0.9625, Test Acc: 0.9100, lr: 0.0015625\n",
      "Epoch: 054, Train Acc: 0.9525, Test Acc: 0.9050, lr: 0.0015625\n",
      "Epoch: 055, Train Acc: 0.9675, Test Acc: 0.9100, lr: 0.0015625\n",
      "Epoch: 056, Train Acc: 0.9675, Test Acc: 0.9150, lr: 0.0015625\n",
      "Epoch: 057, Train Acc: 0.9650, Test Acc: 0.9150, lr: 0.0015625\n",
      "Epoch: 058, Train Acc: 0.9600, Test Acc: 0.9050, lr: 0.0015625\n",
      "Epoch: 059, Train Acc: 0.9725, Test Acc: 0.9200, lr: 0.0015625\n",
      "Epoch: 060, Train Acc: 0.9675, Test Acc: 0.9200, lr: 0.00078125\n",
      "Epoch: 061, Train Acc: 0.9675, Test Acc: 0.9050, lr: 0.00078125\n",
      "Epoch: 062, Train Acc: 0.9725, Test Acc: 0.9150, lr: 0.00078125\n",
      "Epoch: 063, Train Acc: 0.9675, Test Acc: 0.9100, lr: 0.00078125\n",
      "Epoch: 064, Train Acc: 0.9675, Test Acc: 0.9150, lr: 0.00078125\n",
      "Epoch: 065, Train Acc: 0.9650, Test Acc: 0.9100, lr: 0.00078125\n",
      "Epoch: 066, Train Acc: 0.9675, Test Acc: 0.9100, lr: 0.00078125\n",
      "Epoch: 067, Train Acc: 0.9675, Test Acc: 0.9150, lr: 0.00078125\n",
      "Epoch: 068, Train Acc: 0.9725, Test Acc: 0.9100, lr: 0.00078125\n",
      "Epoch: 069, Train Acc: 0.9700, Test Acc: 0.9100, lr: 0.00078125\n",
      "Epoch: 070, Train Acc: 0.9650, Test Acc: 0.9150, lr: 0.000390625\n",
      "Epoch: 071, Train Acc: 0.9725, Test Acc: 0.9150, lr: 0.000390625\n",
      "Epoch: 072, Train Acc: 0.9725, Test Acc: 0.9150, lr: 0.000390625\n",
      "Epoch: 073, Train Acc: 0.9650, Test Acc: 0.9200, lr: 0.000390625\n",
      "Epoch: 074, Train Acc: 0.9725, Test Acc: 0.9150, lr: 0.000390625\n",
      "Epoch: 075, Train Acc: 0.9625, Test Acc: 0.9100, lr: 0.000390625\n",
      "Epoch: 076, Train Acc: 0.9675, Test Acc: 0.9150, lr: 0.000390625\n",
      "Epoch: 077, Train Acc: 0.9650, Test Acc: 0.9100, lr: 0.000390625\n",
      "Epoch: 078, Train Acc: 0.9675, Test Acc: 0.9150, lr: 0.000390625\n",
      "Epoch: 079, Train Acc: 0.9675, Test Acc: 0.9200, lr: 0.000390625\n",
      "Epoch: 080, Train Acc: 0.9650, Test Acc: 0.9100, lr: 0.0001953125\n",
      "Epoch: 081, Train Acc: 0.9725, Test Acc: 0.9200, lr: 0.0001953125\n",
      "Epoch: 082, Train Acc: 0.9725, Test Acc: 0.9200, lr: 0.0001953125\n",
      "Epoch: 083, Train Acc: 0.9700, Test Acc: 0.9100, lr: 0.0001953125\n",
      "Epoch: 084, Train Acc: 0.9725, Test Acc: 0.9200, lr: 0.0001953125\n",
      "Epoch: 085, Train Acc: 0.9675, Test Acc: 0.9150, lr: 0.0001953125\n",
      "Epoch: 086, Train Acc: 0.9725, Test Acc: 0.9150, lr: 0.0001953125\n",
      "Epoch: 087, Train Acc: 0.9700, Test Acc: 0.9150, lr: 0.0001953125\n",
      "Epoch: 088, Train Acc: 0.9675, Test Acc: 0.9100, lr: 0.0001953125\n",
      "Epoch: 089, Train Acc: 0.9750, Test Acc: 0.9200, lr: 0.0001953125\n",
      "Epoch: 090, Train Acc: 0.9750, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 091, Train Acc: 0.9725, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 092, Train Acc: 0.9750, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 093, Train Acc: 0.9725, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 094, Train Acc: 0.9750, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 095, Train Acc: 0.9750, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 096, Train Acc: 0.9750, Test Acc: 0.9100, lr: 9.765625e-05\n",
      "Epoch: 097, Train Acc: 0.9775, Test Acc: 0.9100, lr: 9.765625e-05\n",
      "Epoch: 098, Train Acc: 0.9700, Test Acc: 0.9150, lr: 9.765625e-05\n",
      "Epoch: 099, Train Acc: 0.9725, Test Acc: 0.9150, lr: 9.765625e-05\n"
     ]
    }
   ],
   "source": [
    "from graph_data import GraphData\n",
    "from models import DeeperGCN\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "graph_data = GraphData()\n",
    "\n",
    "\n",
    "# model = GCN(hidden_channels=64)\n",
    "model = DeeperGCN(5, 256, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05) \n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in graph_data.train_loader: # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    train()\n",
    "    train_acc = test(graph_data.train_loader)\n",
    "    test_acc = test(graph_data.test_loader)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, lr: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be45d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'gnn.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
